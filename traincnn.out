

================================
Get the Garden Data
================================


hibiscus  2.8%  5.6%  8.5% 11.3% 14.1% 16.9% 19.7% 22.5% 25.4% 28.2% 31.0% 33.8% 36.6% 39.4% 42.3% 45.1% 47.9% 50.7% 53.5% 56.3% 59.2% 62.0% 64.8% 67.6% 70.4% 73.2% 76.1% 78.9% 81.7% 84.5% 87.3% 90.1% 93.0% 95.8% 98.6% 100.0%
begonia  2.8%  5.7%  8.5% 11.3% 14.2% 17.0% 19.8% 22.7% 25.5% 28.3% 31.2% 34.0% 36.8% 39.7% 42.5% 45.3% 48.2% 51.0% 53.8% 56.7% 59.5% 62.3% 65.2% 68.0% 70.8% 73.7% 76.5% 79.3% 82.2% 85.0% 87.8% 90.7% 93.5% 96.3% 99.2% 100.0%
hosta  2.9%  5.8%  8.8% 11.7% 14.6% 17.5% 20.5% 23.4% 26.3% 29.2% 32.2% 35.1% 38.0% 40.9% 43.9% 46.8% 49.7% 52.6% 55.6% 58.5% 61.4% 64.3% 67.3% 70.2% 73.1% 76.0% 78.9% 81.9% 84.8% 87.7% 90.6% 93.6% 96.5% 99.4% 100.0%
iris  3.6%  7.1% 10.7% 14.2% 17.8% 21.4% 24.9% 28.5% 32.0% 35.6% 39.1% 42.7% 46.3% 49.8% 53.4% 56.9% 60.5% 64.1% 67.6% 71.2% 74.7% 78.3% 81.9% 85.4% 89.0% 92.5% 96.1% 99.6% 100.0%
coleus  3.6%  7.2% 10.9% 14.5% 18.1% 21.7% 25.4% 29.0% 32.6% 36.2% 39.9% 43.5% 47.1% 50.7% 54.3% 58.0% 61.6% 65.2% 68.8% 72.5% 76.1% 79.7% 83.3% 87.0% 90.6% 94.2% 97.8% 100.0%


================================
Get the Garden Graph
================================


Weight_Variable  Parametes  [11, 11, 3, 32] , Count : 11616
Weight_Variable  Parametes  [5, 5, 32, 64] , Count : 51200
Weight_Variable  Parametes  [3, 3, 64, 64] , Count : 36864
Weight_Variable  Parametes  [3, 3, 64, 64] , Count : 36864
Weight_Variable  Parametes  [64, 5] , Count : 320


================================
Show the graph sizes for
processing a batch of 4 images
================================


     (4, 120, 120, 3) batch_normalization/cond/Merge:0
     (4, 22, 22, 32) conv_relu:0
     (4, 18, 18, 64) conv_relu_1:0
     (4, 9, 9, 64) MaxPool:0
     (4, 7, 7, 64) conv_relu_2:0
     (4, 5, 5, 64) conv_3:0
     (4, 1, 1, 64) MaxPool_1:0
     (4, 64) image_to_vector:0
     (4, 64) dropout/mul:0
     (4, 5) label_out:0


================================
Define the training cycle
================================




================================
Do 250 training Epochs
================================


epoch 0 error 0.780000001192 loss 1.60969   test error 0.730000019073 loss 1.59626
epoch 5 error 0.639999985695 loss 1.37787   test error 0.640000015497 loss 1.37304
epoch 10 error 0.620000004768 loss 1.365   test error 0.629999995232 loss 1.3151
epoch 15 error 0.540000021458 loss 1.33747   test error 0.620000004768 loss 1.29881
epoch 20 error 0.539999991655 loss 1.37473   test error 0.580000042915 loss 1.27764
epoch 25 error 0.480000019073 loss 1.29916   test error 0.550000011921 loss 1.25999
epoch 30 error 0.460000038147 loss 1.16283   test error 0.560000002384 loss 1.23773
epoch 35 error 0.44000005722 loss 1.2137   test error 0.5 loss 1.2052
epoch 40 error 0.5 loss 1.12272   test error 0.510000020266 loss 1.16846
epoch 45 error 0.5 loss 1.18183   test error 0.47000002861 loss 1.15301
epoch 50 error 0.399999976158 loss 1.12949   test error 0.509999990463 loss 1.12611
epoch 55 error 0.560000002384 loss 1.21788   test error 0.47000002861 loss 1.10157
epoch 60 error 0.520000010729 loss 1.29619   test error 0.450000047684 loss 1.07551
epoch 65 error 0.399999976158 loss 1.03117   test error 0.439999997616 loss 1.06117
epoch 70 error 0.480000019073 loss 1.25135   test error 0.399999976158 loss 1.03601
epoch 75 error 0.300000011921 loss 0.961425   test error 0.430000007153 loss 1.03484
epoch 80 error 0.399999976158 loss 1.10261   test error 0.410000026226 loss 1.01122
epoch 85 error 0.340000033379 loss 1.00266   test error 0.389999985695 loss 0.989142
epoch 90 error 0.379999995232 loss 0.949828   test error 0.330000042915 loss 0.968967
epoch 95 error 0.360000014305 loss 1.04017   test error 0.399999976158 loss 0.943566
epoch 100 error 0.480000019073 loss 1.02425   test error 0.360000014305 loss 0.945007
epoch 105 error 0.300000011921 loss 0.827964   test error 0.320000052452 loss 0.953162
epoch 110 error 0.320000052452 loss 0.732456   test error 0.350000023842 loss 0.931495
epoch 115 error 0.22000002861 loss 0.843954   test error 0.399999976158 loss 0.935895
epoch 120 error 0.360000014305 loss 0.944085   test error 0.330000042915 loss 0.93227
epoch 125 error 0.360000014305 loss 0.966688   test error 0.310000061989 loss 0.915743
epoch 130 error 0.340000033379 loss 0.998723   test error 0.350000023842 loss 0.913588
epoch 135 error 0.420000016689 loss 1.01206   test error 0.290000021458 loss 0.893438
epoch 140 error 0.340000033379 loss 0.806334   test error 0.300000011921 loss 0.882282
epoch 145 error 0.300000011921 loss 0.969763   test error 0.350000023842 loss 0.97157
epoch 150 error 0.240000009537 loss 0.697857   test error 0.290000021458 loss 0.873042
epoch 155 error 0.319999992847 loss 0.896644   test error 0.350000023842 loss 0.894937
epoch 160 error 0.300000011921 loss 0.811523   test error 0.340000033379 loss 0.901012
epoch 165 error 0.280000030994 loss 0.785738   test error 0.300000011921 loss 0.860667
epoch 170 error 0.22000002861 loss 0.672651   test error 0.320000052452 loss 0.901394
epoch 175 error 0.320000052452 loss 0.695594   test error 0.330000042915 loss 0.888467
epoch 180 error 0.300000011921 loss 0.857045   test error 0.330000042915 loss 0.887602
epoch 185 error 0.180000066757 loss 0.560342   test error 0.300000011921 loss 0.860915
epoch 190 error 0.240000009537 loss 0.696731   test error 0.320000052452 loss 0.861344
epoch 195 error 0.22000002861 loss 0.599382   test error 0.300000011921 loss 0.83396
epoch 200 error 0.260000050068 loss 0.765514   test error 0.310000061989 loss 0.857811
epoch 205 error 0.159999966621 loss 0.474623   test error 0.269999980927 loss 0.844768
epoch 210 error 0.22000002861 loss 0.590494   test error 0.340000033379 loss 0.911465
epoch 215 error 0.259999990463 loss 0.709383   test error 0.270000040531 loss 0.798351
epoch 220 error 0.120000004768 loss 0.444289   test error 0.290000021458 loss 0.855881
epoch 225 error 0.120000004768 loss 0.561739   test error 0.280000030994 loss 0.849924
epoch 230 error 0.27999997139 loss 0.754237   test error 0.310000061989 loss 0.832775
epoch 235 error 0.22000002861 loss 0.581861   test error 0.300000071526 loss 0.876567
epoch 240 error 0.160000085831 loss 0.646647   test error 0.270000040531 loss 0.833052
epoch 245 error 0.139999985695 loss 0.535947   test error 0.300000011921 loss 0.849439


================================
Show the confusion matrix
================================




================================
How close were the estimates
================================


98 / 100  = 98.0 % are in the top 5
This is the breakdown (position 5 = top , position 0 = flop) :
    position 0 count 2
    position 1 count 5
    position 2 count 9
    position 3 count 18
    position 4 count 66
    position 5 count 0
The most accurate labels are : ['hibiscus' 'hosta' 'coleus' 'begonia' 'iris']


================================
Save the model to disk
================================


